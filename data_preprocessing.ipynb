{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from textstat import flesch_reading_ease\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from skimage import io\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import kurtosis  # Added for sharpness estimation\n",
    "import fasttext.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e743dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "category_reviews = \"raw_review_All_Beauty\"\n",
    "category_meta = \"raw_meta_All_Beauty\"\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset_reviews = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", category_reviews, split=\"full\")\n",
    "dataset_meta = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", category_meta, split=\"full\")\n",
    "\n",
    "# ✅ Step 1: Remove reviews with 0 helpful votes BEFORE sampling\n",
    "dataset_reviews = dataset_reviews.filter(lambda x: x[\"helpful_vote\"] > 0)\n",
    "\n",
    "# ✅ Step 2: Sample 10% of filtered data\n",
    "num_samples = int(len(dataset_reviews) * 0.1)\n",
    "dataset_reviews = dataset_reviews.shuffle(seed=42).select(range(num_samples))\n",
    "\n",
    "num_samples_meta = int(len(dataset_meta) * 0.1)\n",
    "dataset_meta = dataset_meta.shuffle(seed=42).select(range(num_samples_meta))\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df_reviews = dataset_reviews.to_pandas()\n",
    "df_meta = dataset_meta.to_pandas()\n",
    "\n",
    "# Display the shape of the dataset\n",
    "print(f\"Filtered dataset size (before sampling): {len(dataset_reviews)} reviews\")\n",
    "print(f\"Sampled dataset size (after selecting 10%): {df_reviews.shape[0]} reviews\")\n",
    "\n",
    "# Optionally save the final filtered dataset\n",
    "df_reviews.to_csv(\"filtered_sampled_reviews.csv\", index=False)\n",
    "print(\"Final dataset saved as filtered_sampled_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959afdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df_reviews.dropna(subset=['text'], inplace=True)\n",
    "df_reviews.fillna({'helpful_vote': 0}, inplace=True)\n",
    "df_meta['price'] = pd.to_numeric(df_meta['price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge reviews with metadata on 'parent_asin'\n",
    "df = pd.merge(df_reviews, df_meta, on='parent_asin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7cadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['helpfulness_score'] = df['helpful_vote'] / (df['helpful_vote'].max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f261339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLP Models\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32267e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning\n",
    "df['cleaned_text'] = df['text'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd770b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FastText Model\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # Download model\n",
    "ft = fasttext.load_model('cc.en.300.bin')  # Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FastText Embeddings\n",
    "def get_fasttext_embedding(text):\n",
    "    words = text.split()\n",
    "    word_vectors = [ft.get_word_vector(word) for word in words]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fasttext_embedding'] = df['cleaned_text'].apply(get_fasttext_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e007fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Other Text Features\n",
    "df['sentiment'] = df['cleaned_text'].apply(lambda t: sia.polarity_scores(t)['compound'])\n",
    "df['readability'] = df['cleaned_text'].apply(flesch_reading_ease)\n",
    "df['review_length'] = df['cleaned_text'].apply(len)\n",
    "df['punctuation_count'] = df['text'].apply(lambda t: t.count(\".\") if isinstance(t, str) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970e28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import sobel\n",
    "\n",
    "def estimate_image_quality(img):\n",
    "    \"\"\" Compute an optimized quality score using Laplacian (blur), mean brightness, and Sobel (sharpness). \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Blur detection (Laplacian variance with slight Gaussian smoothing for noise reduction)\n",
    "    blur_score = cv2.Laplacian(cv2.GaussianBlur(gray, (3,3), 0), cv2.CV_64F).var()\n",
    "\n",
    "    # Brightness (Mean pixel value)\n",
    "    brightness = np.mean(gray)\n",
    "\n",
    "    # Faster Sharpness Estimation using Sobel Edge Magnitude\n",
    "    sobel_x = sobel(gray, axis=0, mode='constant')\n",
    "    sobel_y = sobel(gray, axis=1, mode='constant')\n",
    "    sharpness = np.mean(np.sqrt(sobel_x**2 + sobel_y**2))\n",
    "\n",
    "    # Weighted quality score (adjust weights if needed)\n",
    "    quality_score = (blur_score * (-0.1)) + (sharpness * 0.7) + (brightness * 0.4)\n",
    "\n",
    "    return quality_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f51c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images\n",
    "def process_image(img_url):\n",
    "    try:\n",
    "        img = io.imread(img_url)\n",
    "        return estimate_image_quality(img)\n",
    "    except:\n",
    "        return None  # Return None if the image cannot be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract image URLs safely\n",
    "def extract_image_urls(image_dict):\n",
    "    \"\"\" Extract all available image URLs as a list. \"\"\"\n",
    "    if isinstance(image_dict, dict):\n",
    "        urls = []\n",
    "        for key in ['hi_res', 'large', 'thumb']:\n",
    "            if key in image_dict:\n",
    "                url = image_dict[key]\n",
    "                urls.append(url[0] if isinstance(url, (list, np.ndarray)) else url)\n",
    "        return urls if urls else None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and store URLs as a list in a single column\n",
    "df['image_urls'] = df['images_y'].apply(extract_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ff32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_quality(urls):\n",
    "    if not urls:\n",
    "        return None  # Skip if there are no URLs\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        scores = list(executor.map(process_image, urls))\n",
    "    scores = [s for s in scores if s is not None]  # Remove None values\n",
    "    return np.mean(scores) if scores else None  # Compute average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Apply tqdm progress bar\n",
    "tqdm.pandas(desc=\"Processing Images\")\n",
    "\n",
    "# Apply function with progress bar\n",
    "df['avg_quality_score'] = df['image_urls'].progress_apply(compute_average_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata Features\n",
    "df['verified_purchase'] = df['verified_purchase'].astype(int)\n",
    "df['has_image'] = df['avg_quality_score'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install CLIP and image libraries\n",
    "%pip install transformers torchvision pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def get_image_embedding(url):\n",
    "    try:\n",
    "        image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            embedding = clip_model.get_image_features(**inputs)\n",
    "        return embedding.squeeze().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Image error for {url}: {e}\")\n",
    "        return np.zeros(512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def chunk_text(text, chunk_size=128, stride=32):\n",
    "    tokens = tokenizer(text, truncation=False, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - stride):\n",
    "        chunk = tokens[i:i+chunk_size]\n",
    "        chunks.append(chunk.tolist())\n",
    "        if i + chunk_size >= len(tokens):\n",
    "            break\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da389fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Convert review time to datetime and days since\n",
    "df_reviews['review_date'] = pd.to_datetime(df_reviews['review_date'], errors='coerce')\n",
    "df_reviews['days_since_review'] = (datetime.now() - df_reviews['review_date']).dt.days\n",
    "\n",
    "# Normalize helpful votes and review length\n",
    "df_reviews['review_length'] = df_reviews['review_body'].apply(lambda x: len(x.split()))\n",
    "df_reviews['helpfulness_score'] = df_reviews['helpful_vote'] / df_reviews['total_vote'].replace(0, 1)\n",
    "\n",
    "# Apply readability and sentiment score\n",
    "df_reviews['flesch'] = df_reviews['review_body'].apply(flesch_reading_ease)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df_reviews['sentiment'] = df_reviews['review_body'].apply(lambda x: sia.polarity_scores(x)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: If your metadata has image URLs\n",
    "if 'imageURLHighRes' in df_meta.columns:\n",
    "    df_meta['image_embedding'] = df_meta['imageURLHighRes'].apply(lambda x: get_image_embedding(x[0]) if isinstance(x, list) and len(x) > 0 else np.zeros(512))\n",
    "\n",
    "# Merge metadata with reviews\n",
    "df_merged = df_reviews.merge(df_meta, on='asin', how='left')\n",
    "\n",
    "# Chunk the review text\n",
    "df_merged['text_chunks'] = df_merged['review_body'].apply(chunk_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP-based image-text similarity (alignment) score\n",
    "def image_text_similarity(text, image):\n",
    "    inputs = clip_processor(text=[text], images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = clip_model(**inputs)\n",
    "    return torch.cosine_similarity(outputs.image_embeds, outputs.text_embeds).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d361ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewer-level features (if reviewerID is available)\n",
    "reviewer_stats = df.groupby(\"reviewerID\").agg({\n",
    "    \"reviewText\": \"count\",\n",
    "    \"helpful\": lambda x: sum([h[0]/h[1] if h[1] != 0 else 0 for h in x])\n",
    "}).rename(columns={\n",
    "    \"reviewText\": \"review_count_by_user\",\n",
    "    \"helpful\": \"avg_helpfulness_by_user\"\n",
    "})\n",
    "\n",
    "df = df.merge(reviewer_stats, on=\"reviewerID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target labels\n",
    "def label_helpfulness(row):\n",
    "    if row['total_votes'] == 0:\n",
    "        return \"no_votes\"\n",
    "    ratio = row['helpful_votes'] / row['total_votes']\n",
    "    if ratio >= 0.75:\n",
    "        return \"helpful\"\n",
    "    elif ratio >= 0.5:\n",
    "        return \"somewhat_helpful\"\n",
    "    else:\n",
    "        return \"not_helpful\"\n",
    "\n",
    "df[\"helpfulness_label\"] = df.apply(label_helpfulness, axis=1)\n",
    "df[\"helpfulness_regression\"] = df[\"helpful_votes\"] / df[\"total_votes\"].replace(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06594b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bad data\n",
    "df = df[df['total_votes'] > 0]\n",
    "df = df[df['reviewText'].str.len() > 5]\n",
    "df = df[df['imageURLHighRes'].notna() & df['imageURLHighRes'].str.len() > 0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
