{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72760601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd442c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_data_with_classification_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50647349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_deviation'] = df['rating_number'] - df['average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30904801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_embedding(embed, dim):\n",
    "    try:\n",
    "        if isinstance(embed, str):\n",
    "            embed_str = embed.replace('e+', 'e').replace('[', '').replace(']', '').strip()\n",
    "            embed = [float(x) for x in embed_str.split() if x != '...']\n",
    "            embed = np.array(embed, dtype=np.float32)\n",
    "        elif isinstance(embed, (list, np.ndarray, torch.Tensor)):\n",
    "            embed = np.array(embed, dtype=np.float32)\n",
    "        else:\n",
    "            embed = np.zeros(dim, dtype=np.float32)\n",
    "        if embed.shape[0] != dim:\n",
    "            embed = np.zeros(dim, dtype=np.float32)\n",
    "        if not np.all(np.isfinite(embed)):\n",
    "            embed = np.zeros(dim, dtype=np.float32)\n",
    "        return embed\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing embedding: {e}\")\n",
    "        return np.zeros(dim, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "144339a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dim = 768\n",
    "img_dim = 512\n",
    "df['bert_embedding'] = df['bert_embedding'].apply(lambda x: parse_embedding(x, bert_dim))\n",
    "df['image_embedding'] = df['image_embedding'].apply(lambda x: parse_embedding(x, img_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fef3d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_pca = PCA(n_components=50, random_state=42)\n",
    "img_pca = PCA(n_components=50, random_state=42)\n",
    "bert_reduced = bert_pca.fit_transform(np.stack(df['bert_embedding'].values))\n",
    "img_reduced = img_pca.fit_transform(np.stack(df['image_embedding'].values))\n",
    "df['bert_embedding'] = list(bert_reduced)\n",
    "df['image_embedding'] = list(img_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be11d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified_purchase'] = df['verified_purchase'].astype(int)\n",
    "df['rating_number'] = df['rating_number'].astype(float)\n",
    "df['days_since_review'] = df['days_since_review'].astype(float)\n",
    "df['avg_quality_score'] = df['avg_quality_score'].astype(float)\n",
    "df['average_rating'] = df['average_rating'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc5b2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = ['verified_purchase', 'avg_quality_score', 'days_since_review', 'rating_number', 'average_rating']\n",
    "text_features = ['sentiment', 'readability', 'review_length', 'punctuation_count']\n",
    "new_features = ['rating_deviation']\n",
    "for col in meta_features + text_features + new_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45a88920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39928206",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_to_scale = text_features + meta_features + new_features\n",
    "features_to_scale = [f for f in features_to_scale if f in df.columns]\n",
    "train_df[features_to_scale] = scaler.fit_transform(train_df[features_to_scale])\n",
    "test_df[features_to_scale] = scaler.transform(test_df[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18c2ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "    bert_embeds = np.stack(df['bert_embedding'].values)\n",
    "    img_embeds = np.stack(df['image_embedding'].values)\n",
    "    other_feats = df[features_to_scale].values\n",
    "    features = np.concatenate([bert_embeds, img_embeds, other_feats], axis=1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "875008c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare_features(train_df)\n",
    "X_test = prepare_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5ba37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'helpful_vote' in df.columns:\n",
    "#     max_votes = df['helpful_vote'].max()\n",
    "#     y_train = train_df['helpful_vote'] / max_votes if max_votes > 0 else train_df['helpful_vote']\n",
    "#     y_test = test_df['helpful_vote'] / max_votes if max_votes > 0 else test_df['helpful_vote']\n",
    "\n",
    "if 'helpful_vote' in df.columns:\n",
    "    max_votes = df['helpful_vote'].max()\n",
    "    y_train = np.log1p(train_df['helpful_vote']) / np.log1p(max_votes) if max_votes > 0 else train_df['helpful_vote']\n",
    "    y_test = np.log1p(test_df['helpful_vote']) / np.log1p(max_votes) if max_votes > 0 else test_df['helpful_vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6143b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    "    early_stopping_rounds=50,\n",
    "    task_type='CPU'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4539baae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1381226\ttest: 0.1380375\tbest: 0.1380375 (0)\ttotal: 21.5ms\tremaining: 10.7s\n",
      "50:\tlearn: 0.1273442\ttest: 0.1315786\tbest: 0.1315786 (50)\ttotal: 370ms\tremaining: 3.26s\n",
      "100:\tlearn: 0.1225396\ttest: 0.1308985\tbest: 0.1308524 (96)\ttotal: 696ms\tremaining: 2.75s\n",
      "150:\tlearn: 0.1171076\ttest: 0.1306955\tbest: 0.1306614 (146)\ttotal: 1.17s\tremaining: 2.7s\n",
      "200:\tlearn: 0.1122412\ttest: 0.1306329\tbest: 0.1306003 (196)\ttotal: 1.55s\tremaining: 2.31s\n",
      "250:\tlearn: 0.1075495\ttest: 0.1306583\tbest: 0.1305943 (244)\ttotal: 1.99s\tremaining: 1.97s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.1305942804\n",
      "bestIteration = 244\n",
      "\n",
      "Shrink model to first 245 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x12e19b200>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pool = Pool(X_train, y_train)\n",
    "test_pool = Pool(X_test, y_test)\n",
    "catboost_model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7957bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    r2 = r2_score(y, preds)\n",
    "    pearson_corr, _ = pearsonr(y, preds)\n",
    "    print(f\"Evaluation Results:\\nMSE: {mse:.4f}\\nMAE: {mae:.4f}\\nR²: {r2:.4f}\\nPearson Correlation: {pearson_corr:.4f}\")\n",
    "    return mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "642d34c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "Evaluation Results:\n",
      "MSE: 0.0171\n",
      "MAE: 0.1020\n",
      "R²: 0.1142\n",
      "Pearson Correlation: 0.3380\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set Evaluation:\")\n",
    "mse, mae, r2 = evaluate_model(catboost_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ab0b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and preprocessing objects saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the model and preprocessing objects\n",
    "catboost_model.save_model('catboost_model.cbm')  # Save CatBoost model\n",
    "import pickle\n",
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))  # Save scaler\n",
    "pickle.dump(bert_pca, open('bert_pca.pkl', 'wb'))  # Save BERT PCA\n",
    "pickle.dump(img_pca, open('img_pca.pkl', 'wb'))  # Save image PCA\n",
    "print(\"Model and preprocessing objects saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
